dcc-youlab-gpu-46
Tue Aug  6 07:15:39 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 555.42.02              Driver Version: 555.42.02      CUDA Version: 12.5     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               On  |   00000000:13:00.0 Off |                  Off |
| 30%   17C    P8             15W /  230W |       2MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Using MSE loss function with naive estimator
loading data
number of fasta seq:  2368593
number of counts:  2368593
number of fasta seq:  231129
number of counts:  231129
number of fasta seq:  9
number of counts:  9
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 300, 4)]          0         
                                                                 
 conv1d (Conv1D)             (None, 300, 1024)         33792     
                                                                 
 batch_normalization (Batch  (None, 300, 1024)         4096      
 Normalization)                                                  
                                                                 
 activation (Activation)     (None, 300, 1024)         0         
                                                                 
 dropout (Dropout)           (None, 300, 1024)         0         
                                                                 
 conv1d_1 (Conv1D)           (None, 300, 512)          8389120   
                                                                 
 batch_normalization_1 (Bat  (None, 300, 512)          2048      
 chNormalization)                                                
                                                                 
 activation_1 (Activation)   (None, 300, 512)          0         
                                                                 
 dropout_1 (Dropout)         (None, 300, 512)          0         
                                                                 
 conv1d_2 (Conv1D)           (None, 300, 256)          4194560   
                                                                 
 batch_normalization_2 (Bat  (None, 300, 256)          1024      
 chNormalization)                                                
                                                                 
 activation_2 (Activation)   (None, 300, 256)          0         
                                                                 
 dropout_2 (Dropout)         (None, 300, 256)          0         
                                                                 
 conv1d_3 (Conv1D)           (None, 300, 128)          2097280   
                                                                 
 batch_normalization_3 (Bat  (None, 300, 128)          512       
 chNormalization)                                                
                                                                 
 activation_3 (Activation)   (None, 300, 128)          0         
                                                                 
 dropout_3 (Dropout)         (None, 300, 128)          0         
                                                                 
 conv1d_4 (Conv1D)           (None, 300, 64)           1048640   
                                                                 
 batch_normalization_4 (Bat  (None, 300, 64)           256       
 chNormalization)                                                
                                                                 
 activation_4 (Activation)   (None, 300, 64)           0         
                                                                 
 average_pooling1d (Average  (None, 1, 64)             0         
 Pooling1D)                                                      
                                                                 
 K562 (Dense)                (None, 1, 1)              65        
                                                                 
=================================================================
Total params: 15771393 (60.16 MB)
Trainable params: 15767425 (60.15 MB)
Non-trainable params: 3968 (15.50 KB)
_________________________________________________________________
Training...
Training set: (2368593, 300, 4)
Epoch 1/200
18505/18505 - 2634s - loss: 0.0138 - val_loss: 0.0122 - 2634s/epoch - 142ms/step
Epoch 2/200
18505/18505 - 2531s - loss: 0.0114 - val_loss: 0.0112 - 2531s/epoch - 137ms/step
Epoch 3/200
18505/18505 - 2598s - loss: 0.0107 - val_loss: 0.0107 - 2598s/epoch - 140ms/step
Epoch 4/200
18505/18505 - 2606s - loss: 0.0104 - val_loss: 0.0105 - 2606s/epoch - 141ms/step
Epoch 5/200
18505/18505 - 2623s - loss: 0.0102 - val_loss: 0.0105 - 2623s/epoch - 142ms/step
Epoch 6/200
18505/18505 - 2587s - loss: 0.0100 - val_loss: 0.0103 - 2587s/epoch - 140ms/step
Epoch 7/200
18505/18505 - 2531s - loss: 0.0098 - val_loss: 0.0103 - 2531s/epoch - 137ms/step
Epoch 8/200
18505/18505 - 2523s - loss: 0.0097 - val_loss: 0.0103 - 2523s/epoch - 136ms/step
Epoch 9/200
18505/18505 - 2489s - loss: 0.0096 - val_loss: 0.0102 - 2489s/epoch - 135ms/step
Epoch 10/200
18505/18505 - 2498s - loss: 0.0095 - val_loss: 0.0103 - 2498s/epoch - 135ms/step
Epoch 11/200
18505/18505 - 2490s - loss: 0.0094 - val_loss: 0.0104 - 2490s/epoch - 135ms/step
Epoch 12/200
18505/18505 - 2500s - loss: 0.0093 - val_loss: 0.0105 - 2500s/epoch - 135ms/step
Epoch 13/200
18505/18505 - 2517s - loss: 0.0092 - val_loss: 0.0104 - 2517s/epoch - 136ms/step
Epoch 14/200
18505/18505 - 2496s - loss: 0.0091 - val_loss: 0.0104 - 2496s/epoch - 135ms/step
Epoch 15/200
18505/18505 - 2499s - loss: 0.0091 - val_loss: 0.0102 - 2499s/epoch - 135ms/step
Epoch 16/200
18505/18505 - 2497s - loss: 0.0090 - val_loss: 0.0105 - 2497s/epoch - 135ms/step
Epoch 17/200
18505/18505 - 2498s - loss: 0.0090 - val_loss: 0.0104 - 2498s/epoch - 135ms/step
Epoch 18/200
18505/18505 - 2496s - loss: 0.0089 - val_loss: 0.0105 - 2496s/epoch - 135ms/step
Epoch 19/200
18505/18505 - 2496s - loss: 0.0088 - val_loss: 0.0102 - 2496s/epoch - 135ms/step
Epoch 20/200
18505/18505 - 2498s - loss: 0.0088 - val_loss: 0.0103 - 2498s/epoch - 135ms/step
Epoch 21/200
18505/18505 - 2485s - loss: 0.0088 - val_loss: 0.0103 - 2485s/epoch - 134ms/step
Epoch 22/200
18505/18505 - 2448s - loss: 0.0087 - val_loss: 0.0106 - 2448s/epoch - 132ms/step
Epoch 23/200
18505/18505 - 2496s - loss: 0.0086 - val_loss: 0.0103 - 2496s/epoch - 135ms/step
Epoch 24/200
18505/18505 - 2493s - loss: 0.0086 - val_loss: 0.0102 - 2493s/epoch - 135ms/step
Epoch 25/200
18505/18505 - 2450s - loss: 0.0086 - val_loss: 0.0102 - 2450s/epoch - 132ms/step
Epoch 26/200
18505/18505 - 2448s - loss: 0.0085 - val_loss: 0.0101 - 2448s/epoch - 132ms/step
Epoch 27/200
18505/18505 - 2443s - loss: 0.0085 - val_loss: 0.0102 - 2443s/epoch - 132ms/step
Epoch 28/200
18505/18505 - 2443s - loss: 0.0085 - val_loss: 0.0105 - 2443s/epoch - 132ms/step
Epoch 29/200
18505/18505 - 2437s - loss: 0.0084 - val_loss: 0.0107 - 2437s/epoch - 132ms/step
Epoch 30/200
18505/18505 - 2469s - loss: 0.0084 - val_loss: 0.0104 - 2469s/epoch - 133ms/step
Epoch 31/200
18505/18505 - 2461s - loss: 0.0084 - val_loss: 0.0102 - 2461s/epoch - 133ms/step
Epoch 32/200
18505/18505 - 2454s - loss: 0.0083 - val_loss: 0.0104 - 2454s/epoch - 133ms/step
Epoch 33/200
18505/18505 - 2466s - loss: 0.0083 - val_loss: 0.0102 - 2466s/epoch - 133ms/step
Epoch 34/200
18505/18505 - 2450s - loss: 0.0083 - val_loss: 0.0103 - 2450s/epoch - 132ms/step
Epoch 35/200
18505/18505 - 2469s - loss: 0.0082 - val_loss: 0.0103 - 2469s/epoch - 133ms/step
Epoch 36/200
18505/18505 - 2425s - loss: 0.0082 - val_loss: 0.0104 - 2425s/epoch - 131ms/step
{'loss': [0.013804474845528603, 0.011356486938893795, 0.010667119175195694, 0.010361104272305965, 0.010150901041924953, 0.009976595640182495, 0.009835083968937397, 0.009703860618174076, 0.00958244875073433, 0.009481027722358704, 0.009389570914208889, 0.009311175905168056, 0.0092255724593997, 0.009141246788203716, 0.009087474085390568, 0.009018554352223873, 0.008958745747804642, 0.008900859393179417, 0.008842862211167812, 0.008788459934294224, 0.008751495741307735, 0.008693198673427105, 0.008643489331007004, 0.008604410104453564, 0.008568936958909035, 0.008523741737008095, 0.008494156412780285, 0.008451166562736034, 0.008414393290877342, 0.008378895930945873, 0.008355886675417423, 0.008319670334458351, 0.00829403381794691, 0.008255332708358765, 0.008239335380494595, 0.00820063054561615], 'val_loss': [0.012151220813393593, 0.011239293962717056, 0.010670743882656097, 0.010512612760066986, 0.010501827113330364, 0.010313834995031357, 0.010263203643262386, 0.010338498279452324, 0.010224655270576477, 0.010328293778002262, 0.010374432429671288, 0.010539932176470757, 0.010401871986687183, 0.01039030496031046, 0.01021816860884428, 0.010521438904106617, 0.01039259135723114, 0.010455616749823093, 0.010225684382021427, 0.010325386188924313, 0.010341922752559185, 0.010620533488690853, 0.010259819217026234, 0.010160994715988636, 0.01021743193268776, 0.010116877034306526, 0.010230154730379581, 0.010486590676009655, 0.010699467733502388, 0.010429651476442814, 0.010181039571762085, 0.010352931916713715, 0.010227692313492298, 0.010326110757887363, 0.010254825465381145, 0.010355319827795029]}
Done training
loss [0.013804474845528603, 0.011356486938893795, 0.010667119175195694, 0.010361104272305965, 0.010150901041924953, 0.009976595640182495, 0.009835083968937397, 0.009703860618174076, 0.00958244875073433, 0.009481027722358704, 0.009389570914208889, 0.009311175905168056, 0.0092255724593997, 0.009141246788203716, 0.009087474085390568, 0.009018554352223873, 0.008958745747804642, 0.008900859393179417, 0.008842862211167812, 0.008788459934294224, 0.008751495741307735, 0.008693198673427105, 0.008643489331007004, 0.008604410104453564, 0.008568936958909035, 0.008523741737008095, 0.008494156412780285, 0.008451166562736034, 0.008414393290877342, 0.008378895930945873, 0.008355886675417423, 0.008319670334458351, 0.00829403381794691, 0.008255332708358765, 0.008239335380494595, 0.00820063054561615]
val_loss [0.012151220813393593, 0.011239293962717056, 0.010670743882656097, 0.010512612760066986, 0.010501827113330364, 0.010313834995031357, 0.010263203643262386, 0.010338498279452324, 0.010224655270576477, 0.010328293778002262, 0.010374432429671288, 0.010539932176470757, 0.010401871986687183, 0.01039030496031046, 0.01021816860884428, 0.010521438904106617, 0.01039259135723114, 0.010455616749823093, 0.010225684382021427, 0.010325386188924313, 0.010341922752559185, 0.010620533488690853, 0.010259819217026234, 0.010160994715988636, 0.01021743193268776, 0.010116877034306526, 0.010230154730379581, 0.010486590676009655, 0.010699467733502388, 0.010429651476442814, 0.010181039571762085, 0.010352931916713715, 0.010227692313492298, 0.010326110757887363, 0.010254825465381145, 0.010355319827795029]
1/1 [==============================] - ETA: 0s1/1 [==============================] - 1s 801ms/step
K562 rho= 0.7833333333333333 p= 0.012519873019449882
Elapsed time: 1525.53 minutes
