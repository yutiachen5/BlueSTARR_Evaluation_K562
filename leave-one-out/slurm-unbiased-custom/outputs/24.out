dcc-majoroslab-gpu-04
Wed Jul  3 16:56:57 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 555.42.02              Driver Version: 555.42.02      CUDA Version: 12.5     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX 6000 Ada Gene...    On  |   00000000:13:00.0 Off |                  Off |
| 30%   51C    P3             81W /  300W |       2MiB /  49140MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Using negative log likelihood loss function
loading data
number of fasta seq:  2368593
number of counts:  2368593
number of fasta seq:  231129
number of counts:  231129
number of fasta seq:  9
number of counts:  9
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 300, 4)]          0         
                                                                 
 conv1d (Conv1D)             (None, 300, 1024)         33792     
                                                                 
 batch_normalization (Batch  (None, 300, 1024)         4096      
 Normalization)                                                  
                                                                 
 activation (Activation)     (None, 300, 1024)         0         
                                                                 
 dropout (Dropout)           (None, 300, 1024)         0         
                                                                 
 conv1d_1 (Conv1D)           (None, 300, 512)          8389120   
                                                                 
 batch_normalization_1 (Bat  (None, 300, 512)          2048      
 chNormalization)                                                
                                                                 
 activation_1 (Activation)   (None, 300, 512)          0         
                                                                 
 dropout_1 (Dropout)         (None, 300, 512)          0         
                                                                 
 conv1d_2 (Conv1D)           (None, 300, 256)          4194560   
                                                                 
 batch_normalization_2 (Bat  (None, 300, 256)          1024      
 chNormalization)                                                
                                                                 
 activation_2 (Activation)   (None, 300, 256)          0         
                                                                 
 dropout_2 (Dropout)         (None, 300, 256)          0         
                                                                 
 conv1d_3 (Conv1D)           (None, 300, 128)          2097280   
                                                                 
 batch_normalization_3 (Bat  (None, 300, 128)          512       
 chNormalization)                                                
                                                                 
 activation_3 (Activation)   (None, 300, 128)          0         
                                                                 
 dropout_3 (Dropout)         (None, 300, 128)          0         
                                                                 
 conv1d_4 (Conv1D)           (None, 300, 64)           1048640   
                                                                 
 batch_normalization_4 (Bat  (None, 300, 64)           256       
 chNormalization)                                                
                                                                 
 activation_4 (Activation)   (None, 300, 64)           0         
                                                                 
 average_pooling1d (Average  (None, 1, 64)             0         
 Pooling1D)                                                      
                                                                 
 K562 (Dense)                (None, 1, 1)              65        
                                                                 
=================================================================
Total params: 15771393 (60.16 MB)
Trainable params: 15767425 (60.15 MB)
Non-trainable params: 3968 (15.50 KB)
_________________________________________________________________
Training...
Training set: (2368593, 300, 4)
Epoch 1/200
18505/18505 - 1969s - loss: 19.0791 - val_loss: 18.9397 - 1969s/epoch - 106ms/step
Epoch 2/200
18505/18505 - 1963s - loss: 18.4134 - val_loss: 18.5624 - 1963s/epoch - 106ms/step
Epoch 3/200
18505/18505 - 1970s - loss: 18.2423 - val_loss: 18.5941 - 1970s/epoch - 106ms/step
Epoch 4/200
18505/18505 - 1958s - loss: 18.1561 - val_loss: 18.4568 - 1958s/epoch - 106ms/step
Epoch 5/200
18505/18505 - 1940s - loss: 18.0946 - val_loss: 18.4158 - 1940s/epoch - 105ms/step
Epoch 6/200
18505/18505 - 1945s - loss: 18.0466 - val_loss: 18.5210 - 1945s/epoch - 105ms/step
Epoch 7/200
18505/18505 - 1915s - loss: 18.0039 - val_loss: 18.5431 - 1915s/epoch - 104ms/step
Epoch 8/200
18505/18505 - 1884s - loss: 17.9689 - val_loss: 18.4118 - 1884s/epoch - 102ms/step
Epoch 9/200
18505/18505 - 1841s - loss: 17.9356 - val_loss: 18.5014 - 1841s/epoch - 100ms/step
Epoch 10/200
18505/18505 - 1852s - loss: 17.9089 - val_loss: 18.4755 - 1852s/epoch - 100ms/step
Epoch 11/200
18505/18505 - 1855s - loss: 17.8809 - val_loss: 18.4755 - 1855s/epoch - 100ms/step
Epoch 12/200
18505/18505 - 1841s - loss: 17.8598 - val_loss: 18.4223 - 1841s/epoch - 99ms/step
Epoch 13/200
18505/18505 - 1806s - loss: 17.8367 - val_loss: 18.6597 - 1806s/epoch - 98ms/step
Epoch 14/200
18505/18505 - 1782s - loss: 17.8180 - val_loss: 18.7435 - 1782s/epoch - 96ms/step
Epoch 15/200
18505/18505 - 1772s - loss: 17.8011 - val_loss: 18.6678 - 1772s/epoch - 96ms/step
Epoch 16/200
18505/18505 - 1642s - loss: 17.7831 - val_loss: 18.6656 - 1642s/epoch - 89ms/step
Epoch 17/200
18505/18505 - 1740s - loss: 17.7653 - val_loss: 18.5722 - 1740s/epoch - 94ms/step
Epoch 18/200
18505/18505 - 1833s - loss: 17.7497 - val_loss: 18.5496 - 1833s/epoch - 99ms/step
{'loss': [19.079120635986328, 18.413393020629883, 18.24234962463379, 18.156070709228516, 18.094558715820312, 18.046552658081055, 18.00389862060547, 17.968908309936523, 17.935626983642578, 17.908939361572266, 17.88088035583496, 17.859769821166992, 17.836681365966797, 17.818038940429688, 17.801145553588867, 17.783124923706055, 17.765316009521484, 17.749671936035156], 'val_loss': [18.939706802368164, 18.562358856201172, 18.59406852722168, 18.456825256347656, 18.415786743164062, 18.52095603942871, 18.54309844970703, 18.411800384521484, 18.50139045715332, 18.475534439086914, 18.475500106811523, 18.42228889465332, 18.659696578979492, 18.743465423583984, 18.667770385742188, 18.665590286254883, 18.57215690612793, 18.549636840820312]}
Done training
loss [19.079120635986328, 18.413393020629883, 18.24234962463379, 18.156070709228516, 18.094558715820312, 18.046552658081055, 18.00389862060547, 17.968908309936523, 17.935626983642578, 17.908939361572266, 17.88088035583496, 17.859769821166992, 17.836681365966797, 17.818038940429688, 17.801145553588867, 17.783124923706055, 17.765316009521484, 17.749671936035156]
val_loss [18.939706802368164, 18.562358856201172, 18.59406852722168, 18.456825256347656, 18.415786743164062, 18.52095603942871, 18.54309844970703, 18.411800384521484, 18.50139045715332, 18.475534439086914, 18.475500106811523, 18.42228889465332, 18.659696578979492, 18.743465423583984, 18.667770385742188, 18.665590286254883, 18.57215690612793, 18.549636840820312]
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 256ms/step
K562 rho= 0.8333333333333333 p= 0.005265691029161748
Elapsed time: 581.18 minutes
