dcc-youlab-gpu-06
Fri Jul 19 06:04:18 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 555.42.02              Driver Version: 555.42.02      CUDA Version: 12.5     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               On  |   00000000:13:00.0 Off |                  Off |
| 30%   18C    P8             16W /  230W |       2MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Using negative log likelihood loss function
loading data
number of fasta seq:  2368593
number of counts:  2368593
number of fasta seq:  231678
number of counts:  231678
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 300, 4)]          0         
                                                                 
 conv1d (Conv1D)             (None, 300, 1024)         33792     
                                                                 
 batch_normalization (Batch  (None, 300, 1024)         4096      
 Normalization)                                                  
                                                                 
 activation (Activation)     (None, 300, 1024)         0         
                                                                 
 dropout (Dropout)           (None, 300, 1024)         0         
                                                                 
 conv1d_1 (Conv1D)           (None, 300, 512)          8389120   
                                                                 
 batch_normalization_1 (Bat  (None, 300, 512)          2048      
 chNormalization)                                                
                                                                 
 activation_1 (Activation)   (None, 300, 512)          0         
                                                                 
 dropout_1 (Dropout)         (None, 300, 512)          0         
                                                                 
 conv1d_2 (Conv1D)           (None, 300, 256)          4194560   
                                                                 
 batch_normalization_2 (Bat  (None, 300, 256)          1024      
 chNormalization)                                                
                                                                 
 activation_2 (Activation)   (None, 300, 256)          0         
                                                                 
 dropout_2 (Dropout)         (None, 300, 256)          0         
                                                                 
 conv1d_3 (Conv1D)           (None, 300, 128)          2097280   
                                                                 
 batch_normalization_3 (Bat  (None, 300, 128)          512       
 chNormalization)                                                
                                                                 
 activation_3 (Activation)   (None, 300, 128)          0         
                                                                 
 dropout_3 (Dropout)         (None, 300, 128)          0         
                                                                 
 conv1d_4 (Conv1D)           (None, 300, 64)           1048640   
                                                                 
 batch_normalization_4 (Bat  (None, 300, 64)           256       
 chNormalization)                                                
                                                                 
 activation_4 (Activation)   (None, 300, 64)           0         
                                                                 
 average_pooling1d (Average  (None, 1, 64)             0         
 Pooling1D)                                                      
                                                                 
 K562 (Dense)                (None, 1, 1)              65        
                                                                 
=================================================================
Total params: 15771393 (60.16 MB)
Trainable params: 15767425 (60.15 MB)
Non-trainable params: 3968 (15.50 KB)
_________________________________________________________________
Training...
Training set: (2368593, 300, 4)
Epoch 1/200
18505/18505 - 2483s - loss: 4.1399 - val_loss: 4.1317 - 2483s/epoch - 134ms/step
Epoch 2/200
18505/18505 - 2462s - loss: 4.0570 - val_loss: 4.0773 - 2462s/epoch - 133ms/step
Epoch 3/200
18505/18505 - 2458s - loss: 4.0266 - val_loss: 4.0421 - 2458s/epoch - 133ms/step
Epoch 4/200
18505/18505 - 2523s - loss: 4.0119 - val_loss: 4.0629 - 2523s/epoch - 136ms/step
Epoch 5/200
18505/18505 - 2584s - loss: 4.0002 - val_loss: 4.0320 - 2584s/epoch - 140ms/step
Epoch 6/200
18505/18505 - 2558s - loss: 3.9901 - val_loss: 4.0343 - 2558s/epoch - 138ms/step
Epoch 7/200
18505/18505 - 2531s - loss: 3.9811 - val_loss: 4.0302 - 2531s/epoch - 137ms/step
Epoch 8/200
18505/18505 - 2546s - loss: 3.9723 - val_loss: 4.0373 - 2546s/epoch - 138ms/step
Epoch 9/200
18505/18505 - 2546s - loss: 3.9650 - val_loss: 4.0510 - 2546s/epoch - 138ms/step
Epoch 10/200
18505/18505 - 2534s - loss: 3.9574 - val_loss: 4.0426 - 2534s/epoch - 137ms/step
Epoch 11/200
18505/18505 - 2475s - loss: 3.9505 - val_loss: 4.0718 - 2475s/epoch - 134ms/step
Epoch 12/200
18505/18505 - 2569s - loss: 3.9442 - val_loss: 4.0621 - 2569s/epoch - 139ms/step
Epoch 13/200
18505/18505 - 2561s - loss: 3.9385 - val_loss: 4.0621 - 2561s/epoch - 138ms/step
Epoch 14/200
18505/18505 - 2579s - loss: 3.9327 - val_loss: 4.0713 - 2579s/epoch - 139ms/step
Epoch 15/200
18505/18505 - 2573s - loss: 3.9278 - val_loss: 4.0482 - 2573s/epoch - 139ms/step
Epoch 16/200
18505/18505 - 2552s - loss: 3.9219 - val_loss: 4.1104 - 2552s/epoch - 138ms/step
Epoch 17/200
18505/18505 - 2566s - loss: 3.9172 - val_loss: 4.0861 - 2566s/epoch - 139ms/step
{'loss': [4.139910697937012, 4.057047367095947, 4.026620388031006, 4.011910438537598, 4.000151634216309, 3.9900739192962646, 3.981078624725342, 3.9723384380340576, 3.9649500846862793, 3.9574224948883057, 3.950512409210205, 3.9442429542541504, 3.938530683517456, 3.932722568511963, 3.927809000015259, 3.9219400882720947, 3.917203903198242], 'val_loss': [4.131734848022461, 4.07734489440918, 4.042096138000488, 4.062932968139648, 4.03200101852417, 4.03425407409668, 4.0301513671875, 4.03729248046875, 4.051036834716797, 4.042644500732422, 4.07175350189209, 4.06206750869751, 4.062097549438477, 4.071328163146973, 4.0481743812561035, 4.1104302406311035, 4.086066246032715]}
Done training
loss [4.139910697937012, 4.057047367095947, 4.026620388031006, 4.011910438537598, 4.000151634216309, 3.9900739192962646, 3.981078624725342, 3.9723384380340576, 3.9649500846862793, 3.9574224948883057, 3.950512409210205, 3.9442429542541504, 3.938530683517456, 3.932722568511963, 3.927809000015259, 3.9219400882720947, 3.917203903198242]
val_loss [4.131734848022461, 4.07734489440918, 4.042096138000488, 4.062932968139648, 4.03200101852417, 4.03425407409668, 4.0301513671875, 4.03729248046875, 4.051036834716797, 4.042644500732422, 4.07175350189209, 4.06206750869751, 4.062097549438477, 4.071328163146973, 4.0481743812561035, 4.1104302406311035, 4.086066246032715]
number of fasta seq:  9
number of counts:  9
1/1 [==============================] - ETA: 0s1/1 [==============================] - 1s 534ms/step
K562 rho= 0.8833333333333333 p= 0.0015905004234978686
Elapsed time: 739.51 minutes
