dcc-youlab-gpu-07
Fri Jul 19 13:42:22 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 555.42.02              Driver Version: 555.42.02      CUDA Version: 12.5     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               On  |   00000000:13:00.0 Off |                  Off |
| 30%   17C    P8             15W /  230W |       2MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Using MSE loss function with naive estimator
loading data
number of fasta seq:  2368593
number of counts:  2368593
number of fasta seq:  231678
number of counts:  231678
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 300, 4)]          0         
                                                                 
 conv1d (Conv1D)             (None, 300, 1024)         33792     
                                                                 
 batch_normalization (Batch  (None, 300, 1024)         4096      
 Normalization)                                                  
                                                                 
 activation (Activation)     (None, 300, 1024)         0         
                                                                 
 dropout (Dropout)           (None, 300, 1024)         0         
                                                                 
 conv1d_1 (Conv1D)           (None, 300, 512)          8389120   
                                                                 
 batch_normalization_1 (Bat  (None, 300, 512)          2048      
 chNormalization)                                                
                                                                 
 activation_1 (Activation)   (None, 300, 512)          0         
                                                                 
 dropout_1 (Dropout)         (None, 300, 512)          0         
                                                                 
 conv1d_2 (Conv1D)           (None, 300, 256)          4194560   
                                                                 
 batch_normalization_2 (Bat  (None, 300, 256)          1024      
 chNormalization)                                                
                                                                 
 activation_2 (Activation)   (None, 300, 256)          0         
                                                                 
 dropout_2 (Dropout)         (None, 300, 256)          0         
                                                                 
 conv1d_3 (Conv1D)           (None, 300, 128)          2097280   
                                                                 
 batch_normalization_3 (Bat  (None, 300, 128)          512       
 chNormalization)                                                
                                                                 
 activation_3 (Activation)   (None, 300, 128)          0         
                                                                 
 dropout_3 (Dropout)         (None, 300, 128)          0         
                                                                 
 conv1d_4 (Conv1D)           (None, 300, 64)           1048640   
                                                                 
 batch_normalization_4 (Bat  (None, 300, 64)           256       
 chNormalization)                                                
                                                                 
 activation_4 (Activation)   (None, 300, 64)           0         
                                                                 
 average_pooling1d (Average  (None, 1, 64)             0         
 Pooling1D)                                                      
                                                                 
 K562 (Dense)                (None, 1, 1)              65        
                                                                 
=================================================================
Total params: 15771393 (60.16 MB)
Trainable params: 15767425 (60.15 MB)
Non-trainable params: 3968 (15.50 KB)
_________________________________________________________________
Training...
Training set: (2368593, 300, 4)
Epoch 1/200
18505/18505 - 2606s - loss: 0.0881 - val_loss: 0.0827 - 2606s/epoch - 141ms/step
Epoch 2/200
18505/18505 - 2565s - loss: 0.0811 - val_loss: 0.0776 - 2565s/epoch - 139ms/step
Epoch 3/200
18505/18505 - 2572s - loss: 0.0782 - val_loss: 0.0774 - 2572s/epoch - 139ms/step
Epoch 4/200
18505/18505 - 2567s - loss: 0.0768 - val_loss: 0.0785 - 2567s/epoch - 139ms/step
Epoch 5/200
18505/18505 - 2568s - loss: 0.0759 - val_loss: 0.0764 - 2568s/epoch - 139ms/step
Epoch 6/200
18505/18505 - 2557s - loss: 0.0749 - val_loss: 0.0760 - 2557s/epoch - 138ms/step
Epoch 7/200
18505/18505 - 2538s - loss: 0.0741 - val_loss: 0.0776 - 2538s/epoch - 137ms/step
Epoch 8/200
18505/18505 - 2531s - loss: 0.0735 - val_loss: 0.0767 - 2531s/epoch - 137ms/step
Epoch 9/200
18505/18505 - 2534s - loss: 0.0729 - val_loss: 0.0755 - 2534s/epoch - 137ms/step
Epoch 10/200
18505/18505 - 2537s - loss: 0.0723 - val_loss: 0.0775 - 2537s/epoch - 137ms/step
Epoch 11/200
18505/18505 - 2533s - loss: 0.0718 - val_loss: 0.0776 - 2533s/epoch - 137ms/step
Epoch 12/200
18505/18505 - 2484s - loss: 0.0713 - val_loss: 0.0762 - 2484s/epoch - 134ms/step
Epoch 13/200
18505/18505 - 2441s - loss: 0.0707 - val_loss: 0.0769 - 2441s/epoch - 132ms/step
Epoch 14/200
18505/18505 - 2441s - loss: 0.0703 - val_loss: 0.0780 - 2441s/epoch - 132ms/step
Epoch 15/200
18505/18505 - 2443s - loss: 0.0699 - val_loss: 0.0772 - 2443s/epoch - 132ms/step
Epoch 16/200
18505/18505 - 2474s - loss: 0.0695 - val_loss: 0.0785 - 2474s/epoch - 134ms/step
Epoch 17/200
18505/18505 - 2446s - loss: 0.0691 - val_loss: 0.0780 - 2446s/epoch - 132ms/step
Epoch 18/200
18505/18505 - 2439s - loss: 0.0688 - val_loss: 0.0795 - 2439s/epoch - 132ms/step
Epoch 19/200
18505/18505 - 2442s - loss: 0.0685 - val_loss: 0.0813 - 2442s/epoch - 132ms/step
{'loss': [0.08808304369449615, 0.08107861876487732, 0.07823825627565384, 0.07684244960546494, 0.07585859298706055, 0.0749267041683197, 0.07414090633392334, 0.0734909325838089, 0.07285289466381073, 0.07230434566736221, 0.07176584005355835, 0.07127407193183899, 0.07073691487312317, 0.07030075788497925, 0.06989097595214844, 0.06946361064910889, 0.0691453143954277, 0.06879711896181107, 0.06845799088478088], 'val_loss': [0.08268609642982483, 0.07757037878036499, 0.07740091532468796, 0.07851424813270569, 0.0763639360666275, 0.07601051777601242, 0.0776488408446312, 0.07672610878944397, 0.07553151249885559, 0.07754015177488327, 0.07755385339260101, 0.07624202221632004, 0.07687339186668396, 0.07802112400531769, 0.07717449218034744, 0.0784720778465271, 0.07802967727184296, 0.07946450263261795, 0.08131526410579681]}
Done training
loss [0.08808304369449615, 0.08107861876487732, 0.07823825627565384, 0.07684244960546494, 0.07585859298706055, 0.0749267041683197, 0.07414090633392334, 0.0734909325838089, 0.07285289466381073, 0.07230434566736221, 0.07176584005355835, 0.07127407193183899, 0.07073691487312317, 0.07030075788497925, 0.06989097595214844, 0.06946361064910889, 0.0691453143954277, 0.06879711896181107, 0.06845799088478088]
val_loss [0.08268609642982483, 0.07757037878036499, 0.07740091532468796, 0.07851424813270569, 0.0763639360666275, 0.07601051777601242, 0.0776488408446312, 0.07672610878944397, 0.07553151249885559, 0.07754015177488327, 0.07755385339260101, 0.07624202221632004, 0.07687339186668396, 0.07802112400531769, 0.07717449218034744, 0.0784720778465271, 0.07802967727184296, 0.07946450263261795, 0.08131526410579681]
number of fasta seq:  9
number of counts:  9
1/1 [==============================] - ETA: 0s1/1 [==============================] - 1s 503ms/step
K562 rho= 0.8666666666666667 p= 0.0024953982859902053
Elapsed time: 816.32 minutes
